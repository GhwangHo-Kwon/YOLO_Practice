import json
import cv2
import torch
from ultralytics import YOLO

# ê²½ë¡œ ì„¤ì •
video_path = './YOLO_V8/Sample_data/robot_fish.mp4'
model = YOLO('./runs/detect/train4/weights/best.pt')  # í•™ìŠµëœ Guppy íƒì§€ ëª¨ë¸

# ë¹„ë””ì˜¤ ì½ê¸°
cap = cv2.VideoCapture(video_path)
fps = cap.get(cv2.CAP_PROP_FPS)

# ì²« í”„ë ˆì„ í™•ì¸ ë° í¬ê¸° ì„¤ì •
ret, frame = cap.read()
if not ret:
    raise RuntimeError("ì˜ìƒì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)
height, width = frame.shape[:2]

# ë¹„ë””ì˜¤ ì €ì¥ ê°ì²´ ì´ˆê¸°í™”
out = cv2.VideoWriter('tracked_robot_fish.mp4',
                      cv2.VideoWriter_fourcc(*'mp4v'),
                      fps, (width, height))

# ì¶”ì ëœ ê°ì²´ ì •ë³´ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì´ˆê¸°í™”
tracked_objects = []

# ğŸ” ì˜ìƒ ì „ì²´ ì¶”ì  ì‹¤í–‰
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # í”„ë ˆì„ íšŒì „
    frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)

    # ğŸ” ê°ì²´ ì¶”ì 
    results = model.track(source=frame, conf=0.6, persist=True, verbose=False, save_txt=True, tracker="./YOLO_V8/bytetrack.yaml")

    # ê²°ê³¼ ì‹œê°í™”
    annotated_frame = results[0].plot()
    out.write(annotated_frame)

    # ì¶”ì ëœ ê°ì²´ ì •ë³´ ìˆ˜ì§‘
    frame_data = []
    for result in results[0].boxes:
        # ê° ê°ì²´ì˜ ID, bbox, confidence ê°’ì„ ì¶”ì¶œ
        obj_id = result.id if result.id is not None else -1  # ê°ì²´ IDê°€ Noneì´ë©´ -1ë¡œ ì²˜ë¦¬
        bbox = result.xywh[0].cpu().numpy().tolist()  # ë°”ìš´ë”© ë°•ìŠ¤ (x, y, w, h)
        conf = result.conf[0].cpu().item()  # ì‹ ë¢°ë„ (Tensorì—ì„œ ê°’ì„ ì¶”ì¶œ)

        # ê°ì²´ ì •ë³´ ë”•ì…”ë„ˆë¦¬ ìƒì„±
        frame_data.append({
            'id': obj_id,
            'bbox': bbox,
            'confidence': conf
        })

    # ì´ í”„ë ˆì„ì˜ ê°ì²´ ì •ë³´ ì €ì¥
    tracked_objects.append(frame_data)

    # ì¶œë ¥
    cv2.imshow("Tracked", annotated_frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# ì¶”ì ëœ ê°ì²´ ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥
# Tensor ê°’ì„ JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ë„ë¡ ë³€í™˜ í›„ ì €ì¥
with open('tracked_robot_fish.json', 'w') as json_file:
    # tracked_objectsì˜ ëª¨ë“  Tensor ê°’ì„ ìˆ«ì ê°’ìœ¼ë¡œ ë³€í™˜
    # (ì˜ˆ: bbox, confidence ë“±)
    def convert_tensor(obj):
        if isinstance(obj, (float, int)):
            return obj
        elif isinstance(obj, list):
            return [convert_tensor(i) for i in obj]
        elif isinstance(obj, dict):
            return {key: convert_tensor(value) for key, value in obj.items()}
        elif isinstance(obj, torch.Tensor):
            return obj.item()  # Tensorì—ì„œ ê°’ì„ ì¶”ì¶œ
        return obj

    json.dump([convert_tensor(frame) for frame in tracked_objects], json_file, indent=4)

cap.release()
out.release()
cv2.destroyAllWindows()
